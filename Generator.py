import random
random.seed(101)
random_pick = random.randint(0,len(text_sequences))
from random import randint
from pickle import load
from keras.models import load_model
from keras.preprocessing.sequence import pad_sequences

def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):
    '''
    INPUTS:
    model : model that was trained on text data
    tokenizer : tokenizer that was fit on text data
    seq_len : length of training sequence
    seed_text : raw string text to serve as the seed
    num_gen_words : number of words to be generated by model
    '''
    output_text = []

    input_text = seed_text
    
    for i in range(num_gen_words):
        
        encoded_text = tokenizer.texts_to_sequences([input_text])[0]
        
        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')
        
        pred_word_ind = model.predict(pad_encoded, verbose=0)[0]
        pred_word_ind = np.argmax(pred_word_ind)
        
        pred_word = tokenizer.index_word[pred_word_ind] 
        
        input_text += ' ' + pred_word
        
        
        output_text.append(pred_word)
        
    return ' '.join(output_text)

random_seed_text = text_sequences[random_pick]
seed_text = ' '.join(random_seed_text)

model2 = load_model('<Name>.h5')
tokenizer2 = load(open('<Name>','rb'))

nam = generate_text(model2,tokenizer2,seq_len,seed_text="The Country of japan",num_gen_words=122)
print(nam)
